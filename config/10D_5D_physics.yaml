MODEL_PARAM: 

  ## INN linear
  nmode : 10
  nelem : 4
  # nelem : [10,12,14,16,10,10,10,10,20,23] # for variable discretization

  ## INN nonlinear
  s_patch : 2
  alpha_dil: 20
  p_order: 2
  radial_basis : "cubicSpline" # Activataion functions
  # radial_basis : 'gaussian1'
  INNactivation : 'polynomial'
  # INNactivation : 'sinusoidal'
  # INNactivation : 'exponential'
  # INNactivation : 'sigmoid'
  # INNactivation : 'tanh'
  # INNactivation : 'gelu'

  ## MLP
  nlayers : 3
  nneurons : 100
  # activation : "relu"
  activation : "sigmoid"

DATA_PARAM:
  
  input_col : [0,1,2,3,4,5,6,7,8,9]
  output_col : [10,11,12,13,14]

  bool_data_generation : True # data is already stored and splitted
  data_size: 100_000
  split_ratio: [0.8,0.2] # [0.7,0.15,0.15]

  bool_normalize: True # whether we normalize the input data or not
  bool_shuffle : True # whether we randomly split the data or not
  
TRAIN_PARAM:
  num_epochs_INN : 1000
  num_epochs_MLP : 1000
  batch_size : 128 # 128
  learning_rate : 1e-3
  bool_train_acc : False
  
  validation_period : 10 # if this is greater than num_epochs, validation will not be conducted
  # validation_period : 1
  bool_denormalize: False # or True, whether we denormalize when measuring errors
  error_type : "mse" # or mse
  patience : 10 # for early stopping

  stopping_loss_train: 4e-4


PLOT:
  bool_plot: False
  plot_in_axis: [3,4] # plot input axis
  plot_out_axis: [0] # plot output axis